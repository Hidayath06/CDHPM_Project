# CDHPM_Project
AI-powered medical chatbot that answers health-related questions using advanced multimodal language models.


# 🩺 AI-Based Medical Chatbot

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![AI](https://img.shields.io/badge/AI-Enabled-brightgreen)
![Healthcare](https://img.shields.io/badge/Domain-Healthcare-lightgrey)
![Status](https://img.shields.io/badge/Project-Prototype-yellow)
![License](https://img.shields.io/badge/License-MIT-blue)

## 🔍 Overview
This project is part of an internship at the **Centre for Digital Health and Precision Medicine (CDHPM)**. It focuses on building an AI-based medical chatbot using **Artificial Intelligence**, **Machine Learning**, and **Natural Language Processing (NLP)** to support both clinicians and patients.

The chatbot can interpret **natural language queries** and **medical images**, providing smart and context-aware health-related responses.

## 🚀 Features

- 🧠 Uses **Groq API** with **Meta LLaMA-4** for multimodal interaction (image + text)
- 📷 Accepts medical images (e.g., rashes) for basic diagnosis support
- 💬 Understands patient queries and provides meaningful explanations
- 📅 Planned integration for medication reminders and follow-up scheduling
- 🤖 Built using Python and modular NLP pipelines

## 🛠️ Technologies Used

- Python
- Groq API
- Meta LLaMA-4 (17B)
- Base64 Image Encoding
- Prompt Engineering
- Natural Language Processing

## 🔮 Future Enhancements

- 🎙️ Voice-to-Voice communication (Speech-to-Text and Text-to-Speech)
- 🌐 Web Interface using Flask or Streamlit
- 🗃️ Patient history storage and query tracking
- 🧾 Expanded medical knowledge base integration

## 📂 Project Status
Currently at prototype stage with successful multimodal input-output interaction. Actively working on UI integration and voice-based communication.
